#!/usr/bin/env python3
"""
SECæŠ¥å‘Šæ•°æ®è·å–å·¥å…·ï¼ˆå¢å¼ºç‰ˆï¼‰

æ ¹æ®å…¬å¸ä»£ç (AAPL)æˆ–CIKã€æŠ¥å‘Šç±»å‹(10-K, 10-Qç­‰)ã€å¹´ä»½ç­‰å‚æ•°ä»SECè·å–å…·ä½“è´¢åŠ¡æ•°æ®
æ”¯æŒä»report_metrics_analysis.jsonä¸­è·å–çš„å…¨é¢æŠ¥å‘Šç±»å‹å’ŒæŒ‡æ ‡

ä½¿ç”¨ç¤ºä¾‹:
    python sec_report_fetcher_enhanced.py --company AAPL --report 10-K --year 2025
    python sec_report_fetcher_enhanced.py --cik 0000320193 --report 10-K --section "Balance Sheet" --year 2020-2025
    python sec_report_fetcher_enhanced.py --company MSFT --report 10-Q --year 2024 --section "Balance Sheet Summary"
"""

import argparse
import sys
import os
import json
import pickle
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Union, Set

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '.'))

from src import SECClient, XBRLFramesClient, DocumentRetriever
import pandas as pd

# ç¼“å­˜é…ç½®
CACHE_FILE_PATH = os.path.join(os.path.dirname(__file__), 'data', 'invalid_concepts_cache.pkl')
CACHE_EXPIRY_DAYS = 7  # ç¼“å­˜æœ‰æ•ˆæœŸï¼š7å¤©

# å…¨å±€ç¼“å­˜å˜é‡
invalid_concepts_cache = {
    'cache_data': {},  # æ ¼å¼: {(cik, report_type, year, concept): timestamp}
    'last_updated': None
}


def load_invalid_concepts_cache() -> Dict:
    """
    åŠ è½½æ— æ•ˆæŒ‡æ ‡ç¼“å­˜æ•°æ®
    
    Returns:
        ç¼“å­˜æ•°æ®å­—å…¸
    """
    global invalid_concepts_cache
    
    try:
        if os.path.exists(CACHE_FILE_PATH):
            with open(CACHE_FILE_PATH, 'rb') as f:
                cache_data = pickle.load(f)
                
                # æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸ
                if 'last_updated' in cache_data:
                    last_updated = cache_data['last_updated']
                    if isinstance(last_updated, datetime):
                        cache_age = datetime.now() - last_updated
                        if cache_age.days <= CACHE_EXPIRY_DAYS:
                            invalid_concepts_cache = cache_data
                            print(f"ğŸ“¦ å·²åŠ è½½æ— æ•ˆæŒ‡æ ‡ç¼“å­˜ï¼ŒåŒ…å« {len(cache_data.get('cache_data', {}))} æ¡è®°å½•")
                            return invalid_concepts_cache
                        else:
                            print(f"â° ç¼“å­˜å·²è¿‡æœŸï¼ˆ{cache_age.days}å¤©ï¼‰ï¼Œå°†é‡æ–°åˆ›å»º")
                
        # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨æˆ–ç¼“å­˜è¿‡æœŸï¼Œåˆå§‹åŒ–æ–°ç¼“å­˜
        invalid_concepts_cache = {
            'cache_data': {},
            'last_updated': datetime.now()
        }
        print(f"ğŸ†• åˆ›å»ºæ–°çš„æ— æ•ˆæŒ‡æ ‡ç¼“å­˜")
        
    except Exception as e:
        print(f"âš ï¸  åŠ è½½ç¼“å­˜æ—¶å‡ºé”™: {e}ï¼Œå°†åˆ›å»ºæ–°ç¼“å­˜")
        invalid_concepts_cache = {
            'cache_data': {},
            'last_updated': datetime.now()
        }
    
    return invalid_concepts_cache


def save_invalid_concepts_cache():
    """
    ä¿å­˜æ— æ•ˆæŒ‡æ ‡ç¼“å­˜åˆ°æ–‡ä»¶
    """
    try:
        # ç¡®ä¿dataç›®å½•å­˜åœ¨
        cache_dir = os.path.dirname(CACHE_FILE_PATH)
        if not os.path.exists(cache_dir):
            os.makedirs(cache_dir)
        
        # æ›´æ–°æœ€åä¿®æ”¹æ—¶é—´
        invalid_concepts_cache['last_updated'] = datetime.now()
        
        with open(CACHE_FILE_PATH, 'wb') as f:
            pickle.dump(invalid_concepts_cache, f)
        
        print(f"ğŸ’¾ å·²ä¿å­˜æ— æ•ˆæŒ‡æ ‡ç¼“å­˜åˆ°: {CACHE_FILE_PATH}")
        
    except Exception as e:
        print(f"âš ï¸  ä¿å­˜ç¼“å­˜æ—¶å‡ºé”™: {e}")


def is_concept_invalid(cik: str, report_type: str, year: int, concept: str) -> bool:
    """
    æ£€æŸ¥æŒ‡å®šçš„æ¦‚å¿µæ˜¯å¦åœ¨æ— æ•ˆç¼“å­˜ä¸­
    
    Args:
        cik: å…¬å¸CIK
        report_type: æŠ¥å‘Šç±»å‹ï¼ˆå¦‚10-K, 10-Qï¼‰
        year: å¹´ä»½
        concept: è´¢åŠ¡æ¦‚å¿µåç§°
        
    Returns:
        å¦‚æœæ¦‚å¿µåœ¨ç¼“å­˜ä¸­ä¸”æœªè¿‡æœŸï¼Œè¿”å›Trueï¼›å¦åˆ™è¿”å›False
    """
    cache_key = (cik, report_type, year, concept)
    
    if cache_key in invalid_concepts_cache['cache_data']:
        cached_time = invalid_concepts_cache['cache_data'][cache_key]
        
        # æ£€æŸ¥ç¼“å­˜é¡¹æ˜¯å¦è¿‡æœŸ
        if isinstance(cached_time, datetime):
            cache_age = datetime.now() - cached_time
            if cache_age.days <= CACHE_EXPIRY_DAYS:
                return True
            else:
                # åˆ é™¤è¿‡æœŸçš„ç¼“å­˜é¡¹
                del invalid_concepts_cache['cache_data'][cache_key]
    
    return False


def add_invalid_concept(cik: str, report_type: str, year: int, concept: str):
    """
    å°†æ— æ•ˆçš„æ¦‚å¿µæ·»åŠ åˆ°ç¼“å­˜ä¸­
    
    Args:
        cik: å…¬å¸CIK
        report_type: æŠ¥å‘Šç±»å‹ï¼ˆå¦‚10-K, 10-Qï¼‰
        year: å¹´ä»½
        concept: è´¢åŠ¡æ¦‚å¿µåç§°
    """
    cache_key = (cik, report_type, year, concept)
    invalid_concepts_cache['cache_data'][cache_key] = datetime.now()


def get_cache_stats() -> Dict:
    """
    è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
    
    Returns:
        ç¼“å­˜ç»Ÿè®¡å­—å…¸
    """
    total_cached = len(invalid_concepts_cache['cache_data'])
    
    # è®¡ç®—è¿‡æœŸçš„ç¼“å­˜é¡¹æ•°é‡
    expired_count = 0
    current_time = datetime.now()
    
    # æŒ‰å…¬å¸å’ŒæŠ¥å‘Šç±»å‹ç»Ÿè®¡
    company_stats = {}
    report_type_stats = {}
    
    for cache_key, cached_time in invalid_concepts_cache['cache_data'].items():
        if isinstance(cached_time, datetime):
            cache_age = current_time - cached_time
            if cache_age.days > CACHE_EXPIRY_DAYS:
                expired_count += 1
            else:
                # ç»Ÿè®¡æœ‰æ•ˆç¼“å­˜
                if len(cache_key) >= 4:  # (cik, report_type, year, concept)
                    cik, report_type, year, concept = cache_key
                    
                    # æŒ‰å…¬å¸ç»Ÿè®¡
                    if cik not in company_stats:
                        company_stats[cik] = 0
                    company_stats[cik] += 1
                    
                    # æŒ‰æŠ¥å‘Šç±»å‹ç»Ÿè®¡
                    if report_type not in report_type_stats:
                        report_type_stats[report_type] = 0
                    report_type_stats[report_type] += 1
    
    return {
        'total_cached': total_cached,
        'expired_count': expired_count,
        'valid_count': total_cached - expired_count,
        'last_updated': invalid_concepts_cache.get('last_updated'),
        'cache_file': CACHE_FILE_PATH,
        'company_stats': company_stats,
        'report_type_stats': report_type_stats
    }


def load_ticker_cik_mapping() -> Dict[str, str]:
    """
    ä»data/ticker.txtæ–‡ä»¶åŠ è½½è‚¡ç¥¨ä»£ç åˆ°CIKçš„æ˜ å°„
    
    Returns:
        è‚¡ç¥¨ä»£ç åˆ°CIKçš„æ˜ å°„å­—å…¸
    """
    ticker_cik_map = {}
    try:
        ticker_file_path = os.path.join(os.path.dirname(__file__), 'data', 'ticker.txt')
        with open(ticker_file_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and '\t' in line:
                    parts = line.split('\t')
                    if len(parts) >= 2:
                        ticker = parts[0].upper()  # ç»Ÿä¸€è½¬æ¢ä¸ºå¤§å†™
                        cik = parts[1].zfill(10)  # ç¡®ä¿CIKæ˜¯10ä½æ•°å­—
                        ticker_cik_map[ticker] = cik
        print(f"ğŸ“Š å·²åŠ è½½ {len(ticker_cik_map)} ä¸ªå…¬å¸çš„è‚¡ç¥¨ä»£ç -CIKæ˜ å°„")
        return ticker_cik_map
    except Exception as e:
        print(f"âš ï¸  æ— æ³•åŠ è½½tickeræ˜ å°„æ–‡ä»¶: {e}")
        return {}


def load_report_metrics_mapping() -> Dict:
    """
    åŠ è½½æŠ¥å‘ŠæŒ‡æ ‡æ˜ å°„æ•°æ®
    
    Returns:
        åŒ…å«æŠ¥å‘Šç±»å‹å’ŒæŒ‡æ ‡æ˜ å°„çš„å­—å…¸
    """
    try:
        with open(os.path.join(os.path.dirname(__file__), 'data', 'report_metrics_analysis.json'), 'r', encoding='utf-8') as f:
            data = json.load(f)
            return data.get('detailed_metrics', {})
    except Exception as e:
        print(f"âš ï¸  æ— æ³•åŠ è½½æŠ¥å‘ŠæŒ‡æ ‡æ˜ å°„æ–‡ä»¶: {e}")
        return {}


def parse_year_range(year_arg: str) -> List[int]:
    """
    è§£æå¹´ä»½å‚æ•°ï¼Œæ”¯æŒå•ä¸€å¹´ä»½æˆ–å¹´ä»½èŒƒå›´
    
    Args:
        year_arg: å¹´ä»½å‚æ•°ï¼Œå¦‚ "2025" æˆ– "2020-2025"
        
    Returns:
        å¹´ä»½åˆ—è¡¨
    """
    if '-' in year_arg:
        start_year, end_year = map(int, year_arg.split('-'))
        if start_year > end_year:
            raise ValueError("èµ·å§‹å¹´ä»½ä¸èƒ½å¤§äºç»“æŸå¹´ä»½")
        return list(range(start_year, end_year + 1))
    else:
        return [int(year_arg)]


def get_company_info(sec_client: SECClient, company_id: str, is_cik: bool = False, ticker_cik_map: Dict[str, str] = None) -> Dict:
    """
    è·å–å…¬å¸ä¿¡æ¯
    
    Args:
        sec_client: SECå®¢æˆ·ç«¯
        company_id: å…¬å¸æ ‡è¯†ï¼ˆè‚¡ç¥¨ä»£ç æˆ–CIKï¼‰
        is_cik: æ˜¯å¦ä¸ºCIK
        ticker_cik_map: è‚¡ç¥¨ä»£ç åˆ°CIKçš„æ˜ å°„
        
    Returns:
        å…¬å¸ä¿¡æ¯å­—å…¸
    """
    if is_cik:
        # éªŒè¯CIKæ ¼å¼
        cik = company_id.zfill(10)  # ç¡®ä¿æ˜¯10ä½æ•°å­—
        # å°è¯•è·å–å…¬å¸æäº¤ä¿¡æ¯æ¥éªŒè¯CIK
        try:
            submissions = sec_client.get_company_submissions(cik)
            company_name = submissions.get('names', ['Unknown Company'])[0] if submissions.get('names') else 'Unknown Company'
            # ä» ticker_cik_map ä¸­åå‘æŸ¥æ‰¾ ticker
            ticker = 'N/A'
            if ticker_cik_map:
                for t, c in ticker_cik_map.items():
                    if c == cik:
                        ticker = t
                        break
            return {
                'cik': cik,
                'ticker': ticker,
                'title': company_name
            }
        except Exception as e:
            raise ValueError(f"æ— æ•ˆçš„CIK {company_id}: {e}")
    else:
        # é€šè¿‡è‚¡ç¥¨ä»£ç æŸ¥æ‰¾å…¬å¸
        ticker_upper = company_id.upper()
        
        # ä¼˜å…ˆä»æœ¬åœ°tickeræ˜ å°„ä¸­æŸ¥æ‰¾
        if ticker_cik_map and ticker_upper in ticker_cik_map:
            cik = ticker_cik_map[ticker_upper]
            print(f"ğŸ“„ ä»æœ¬åœ°æ•°æ®æ‰¾åˆ° {ticker_upper} çš„CIK: {cik}")
            
            # è·å–å…¬å¸åç§°
            try:
                submissions = sec_client.get_company_submissions(cik)
                company_name = submissions.get('names', ['Unknown Company'])[0] if submissions.get('names') else 'Unknown Company'
                return {
                    'cik': cik,
                    'ticker': ticker_upper,
                    'title': company_name
                }
            except Exception as e:
                print(f"âš ï¸  æ— æ³•ä» SEC API è·å–å…¬å¸åç§°: {e}")
                return {
                    'cik': cik,
                    'ticker': ticker_upper,
                    'title': f'{ticker_upper} Inc.'
                }
        
        # å¦‚æœæœ¬åœ°æ•°æ®ä¸­æ²¡æœ‰ï¼Œåˆ™é€šè¿‡SEC APIæŸ¥æ‰¾
        print(f"ğŸ” æœ¬åœ°æ•°æ®ä¸­æœªæ‰¾åˆ° {ticker_upper}ï¼Œå°è¯•é€šè¿‡SEC APIæŸ¥æ‰¾...")
        company_info = sec_client.search_company_by_ticker(company_id)
        if not company_info:
            raise ValueError(f"æœªæ‰¾åˆ°è‚¡ç¥¨ä»£ç  {company_id} å¯¹åº”çš„å…¬å¸")
        return company_info


def get_financial_concepts_by_section(section: str, report_type: str, metrics_mapping: Dict) -> List[str]:
    """
    æ ¹æ®æŠ¥è¡¨éƒ¨åˆ†å’ŒæŠ¥å‘Šç±»å‹è·å–å¯¹åº”çš„è´¢åŠ¡æ¦‚å¿µåˆ—è¡¨
    
    Args:
        section: æŠ¥è¡¨éƒ¨åˆ†åç§°
        report_type: æŠ¥å‘Šç±»å‹
        metrics_mapping: æŠ¥å‘ŠæŒ‡æ ‡æ˜ å°„æ•°æ®
        
    Returns:
        è´¢åŠ¡æ¦‚å¿µåˆ—è¡¨
    """
    # é»˜è®¤çš„è´¢åŠ¡æ¦‚å¿µæ˜ å°„ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
    default_concept_mapping = {
        'balance_sheet': [
            'Assets', 'AssetsCurrent', 'AssetsNoncurrent',
            'Liabilities', 'LiabilitiesCurrent', 'LiabilitiesNoncurrent',
            'StockholdersEquity',
            'CashAndCashEquivalentsAtCarryingValue',
            'AccountsReceivableNetCurrent',
            'InventoryNet',
            'PropertyPlantAndEquipmentNet',
            'LongTermDebtNoncurrent',
            'AccountsPayableCurrent'
        ],
        'income_statement': [
            'Revenues', 'RevenueFromContractWithCustomerExcludingAssessedTax',
            'CostOfRevenue', 'GrossProfit',
            'OperatingExpenses', 'OperatingIncomeLoss',
            'NetIncomeLoss',
            'EarningsPerShareBasic', 'EarningsPerShareDiluted'
        ],
        'cash_flow': [
            'NetCashProvidedByUsedInOperatingActivities',
            'NetCashProvidedByUsedInInvestingActivities',
            'NetCashProvidedByUsedInFinancingActivities',
            'PaymentsToAcquirePropertyPlantAndEquipment',
            'PaymentsOfDividends',
            'PaymentsForRepurchaseOfCommonStock'
        ]
    }
    
    # ä»report_metrics_analysis.jsonä¸­è·å–æŒ‡æ ‡
    if report_type in metrics_mapping and 'sections' in metrics_mapping[report_type]:
        sections = metrics_mapping[report_type]['sections']
        if section in sections:
            # è·å–è¯¥éƒ¨åˆ†çš„æ‰€æœ‰æŒ‡æ ‡åç§°
            section_metrics = sections[section]
            if isinstance(section_metrics, list) and len(section_metrics) > 0:
                # æå–æŒ‡æ ‡åç§°
                concept_names = []
                for metric in section_metrics:
                    if isinstance(metric, dict) and 'metric_name' in metric:
                        concept_names.append(metric['metric_name'])
                    elif isinstance(metric, str):
                        concept_names.append(metric)
                return concept_names
    
    # å›é€€åˆ°é»˜è®¤æ˜ å°„
    section_key = section.lower().replace(' ', '_')
    return default_concept_mapping.get(section_key, default_concept_mapping.get('balance_sheet', []))


def get_all_report_types(metrics_mapping: Dict) -> List[str]:
    """
    è·å–æ‰€æœ‰æ”¯æŒçš„æŠ¥å‘Šç±»å‹
    
    Args:
        metrics_mapping: æŠ¥å‘ŠæŒ‡æ ‡æ˜ å°„æ•°æ®
        
    Returns:
        æŠ¥å‘Šç±»å‹åˆ—è¡¨
    """
    return list(metrics_mapping.keys()) if metrics_mapping else ['10-K', '10-Q']


def get_all_sections_for_report(report_type: str, metrics_mapping: Dict) -> List[str]:
    """
    è·å–æŒ‡å®šæŠ¥å‘Šç±»å‹çš„æ‰€æœ‰éƒ¨åˆ†
    
    Args:
        report_type: æŠ¥å‘Šç±»å‹
        metrics_mapping: æŠ¥å‘ŠæŒ‡æ ‡æ˜ å°„æ•°æ®
        
    Returns:
        éƒ¨åˆ†åç§°åˆ—è¡¨
    """
    if report_type in metrics_mapping and 'sections' in metrics_mapping[report_type]:
        return list(metrics_mapping[report_type]['sections'].keys())
    return []


def fetch_sec_report_data(company_id: str, report_type: str, years: List[int], 
                         section: Optional[str] = None, is_cik: bool = False,
                         user_agent: str = "SEC Report Fetcher <sec.report@example.com>",
                         ticker_cik_map: Dict[str, str] = None) -> pd.DataFrame:
    """
    è·å–SECæŠ¥å‘Šæ•°æ®
    
    Args:
        company_id: å…¬å¸æ ‡è¯†ï¼ˆè‚¡ç¥¨ä»£ç æˆ–CIKï¼‰
        report_type: æŠ¥å‘Šç±»å‹ï¼ˆå¦‚10-K, 10-Qï¼‰
        years: å¹´ä»½åˆ—è¡¨
        section: æŠ¥å‘Šéƒ¨åˆ†
        is_cik: æ˜¯å¦ä¸ºCIK
        user_agent: ç”¨æˆ·ä»£ç†å­—ç¬¦ä¸²
        ticker_cik_map: è‚¡ç¥¨ä»£ç åˆ°CIKçš„æ˜ å°„
        
    Returns:
        åŒ…å«è´¢åŠ¡æ•°æ®çš„DataFrame
    """
    # åˆå§‹åŒ–å®¢æˆ·ç«¯
    sec_client = SECClient(user_agent=user_agent)
    xbrl_client = XBRLFramesClient(sec_client)
    
    # åŠ è½½æŠ¥å‘ŠæŒ‡æ ‡æ˜ å°„
    metrics_mapping = load_report_metrics_mapping()
    
    # åŠ è½½æ— æ•ˆæŒ‡æ ‡ç¼“å­˜
    load_invalid_concepts_cache()
    
    # è·å–å…¬å¸ä¿¡æ¯
    print(f"ğŸ” æ­£åœ¨è·å–å…¬å¸ä¿¡æ¯...")
    company_info = get_company_info(sec_client, company_id, is_cik, ticker_cik_map)
    print(f"ğŸ¢ å…¬å¸: {company_info['title']} (CIK: {company_info['cik']})")
    
    # ç¡®å®šè¦è·å–çš„è´¢åŠ¡æ¦‚å¿µ
    if section:
        concepts = get_financial_concepts_by_section(section, report_type, metrics_mapping)
        print(f"ğŸ“„ æŠ¥å‘Šéƒ¨åˆ†: {section}")
        print(f"ğŸ“ˆ è¯¥éƒ¨åˆ†åŒ…å« {len(concepts)} ä¸ªæŒ‡æ ‡")
    else:
        # å¦‚æœæ²¡æœ‰æŒ‡å®šéƒ¨åˆ†ï¼Œè·å–æ‰€æœ‰ä¸»è¦è´¢åŠ¡æ¦‚å¿µ
        concepts = [
            'Assets', 'Liabilities', 'StockholdersEquity',
            'Revenues', 'NetIncomeLoss', 'OperatingIncomeLoss',
            'CashAndCashEquivalentsAtCarryingValue',
            'AccountsReceivableNetCurrent', 'InventoryNet',
            'PropertyPlantAndEquipmentNet', 'LongTermDebtNoncurrent',
            'EarningsPerShareBasic', 'EarningsPerShareDiluted',
            'NetCashProvidedByUsedInOperatingActivities'
        ]
        print(f"ğŸ“„ è·å–æ‰€æœ‰ä¸»è¦è´¢åŠ¡æ¦‚å¿µ")
    
    print(f"ğŸ“Š æŠ¥å‘Šç±»å‹: {report_type}")
    print(f"ğŸ“… å¹´ä»½: {', '.join(map(str, years))}")
    
    # ç»Ÿè®¡ä¿¡æ¯
    total_concepts = len(concepts)
    cached_skipped = 0
    api_requested = 0
    successful_retrieved = 0
    newly_cached = 0
    
    # æ”¶é›†æ•°æ®
    all_data = []
    
    for year in years:
        print(f"\nğŸ“… æ­£åœ¨è·å– {year} å¹´æ•°æ®...")
        
        for concept in concepts:
            # æ£€æŸ¥æ˜¯å¦åœ¨ç¼“å­˜ä¸­ï¼ˆå·²çŸ¥æ— æ•ˆï¼‰
            if is_concept_invalid(company_info['cik'], report_type, year, concept):
                print(f"â© è·³è¿‡ {concept} (ç¼“å­˜ä¸­å·²çŸ¥æ— æ•ˆ - {report_type} {year})")
                cached_skipped += 1
                continue
            
            try:
                print(f"  ğŸ”„ è·å– {concept}...")
                api_requested += 1
                
                # è·å–å…¬å¸ç‰¹å®šæ¦‚å¿µçš„å†å²æ•°æ®
                concept_data = xbrl_client.get_company_concept_data(
                    cik=company_info['cik'], 
                    concept=concept
                )
                
                if concept_data and 'units' in concept_data:
                    # æŸ¥æ‰¾USDå•ä½æ•°æ®
                    unit_data = concept_data['units'].get('USD', [])
                    
                    if unit_data:
                        # æŸ¥æ‰¾æŒ‡å®šå¹´ä»½çš„æ•°æ®
                        found_data = False
                        for item in unit_data:
                            fiscal_year = item.get('fy', 0)
                            form_type = item.get('form', '')
                            
                            # åŒ¹é…å¹´ä»½å’ŒæŠ¥å‘Šç±»å‹
                            if fiscal_year == year and form_type.upper() == report_type.upper():
                                # æ ¼å¼åŒ–æ•°å€¼
                                value = item.get('val', 0)
                                if isinstance(value, (int, float)):
                                    if abs(value) >= 1e9:
                                        formatted_value = f"${value/1e9:.2f}B"
                                    elif abs(value) >= 1e6:
                                        formatted_value = f"${value/1e6:.2f}M"
                                    elif abs(value) >= 1e3:
                                        formatted_value = f"${value/1e3:.2f}K"
                                    else:
                                        formatted_value = f"${value:,.2f}"
                                else:
                                    formatted_value = str(value)
                                
                                all_data.append({
                                    'company': company_info['title'],
                                    'ticker': company_info.get('ticker', 'N/A'),
                                    'cik': company_info['cik'],
                                    'concept': concept,
                                    'value': value,
                                    'formatted_value': formatted_value,
                                    'year': fiscal_year,
                                    'report_type': form_type,
                                    'end_date': item.get('end', ''),
                                    'start_date': item.get('start', ''),
                                    'filed_date': item.get('filed', ''),
                                    'frame': item.get('frame', '')
                                })
                                print(f"    âœ… {concept}: {formatted_value}")
                                successful_retrieved += 1
                                found_data = True
                                break  # æ‰¾åˆ°åŒ¹é…çš„æ•°æ®åè·³å‡ºå¾ªç¯
                        
                        if not found_data:
                            print(f"    âš ï¸  æœªæ‰¾åˆ° {year} å¹´ {report_type} æŠ¥å‘Šä¸­çš„ {concept} æ•°æ®")
                            # æ²¡æœ‰æ‰¾åˆ°å¯¹åº”å¹´ä»½çš„æ•°æ®ï¼Œä½†ä¸è®¤ä¸ºæ˜¯æ— æ•ˆæ¦‚å¿µ
                    else:
                        print(f"    âš ï¸  {concept} æ²¡æœ‰USDå•ä½æ•°æ®")
                        # USDå•ä½æ•°æ®ä¸å­˜åœ¨ï¼Œå¯èƒ½æ˜¯éè´§å¸ç±»æŒ‡æ ‡ï¼Œä¸ç¼“å­˜
                else:
                    print(f"    âš ï¸  æ— æ³•è·å– {concept} æ•°æ®")
                    # APIè¿”å›ç©ºæ•°æ®æˆ–æ— unitsï¼Œå¯èƒ½æ˜¯æ— æ•ˆæ¦‚å¿µï¼ŒåŠ å…¥ç¼“å­˜
                    add_invalid_concept(company_info['cik'], report_type, year, concept)
                    newly_cached += 1
                    
            except Exception as e:
                error_msg = str(e)
                if "404" in error_msg or "Not Found" in error_msg:
                    print(f"    âŒ æ¦‚å¿µ {concept} åœ¨ {report_type} {year} ä¸­ä¸å­˜åœ¨ï¼ˆ404é”™è¯¯ï¼‰ï¼Œå·²åŠ å…¥ç¼“å­˜")
                    # 404é”™è¯¯ï¼Œè¡¨ç¤ºæ¦‚å¿µåœ¨è¯¥å…¬å¸çš„è¯¥æŠ¥å‘Šä¸­ä¸å­˜åœ¨ï¼ŒåŠ å…¥ç¼“å­˜
                    add_invalid_concept(company_info['cik'], report_type, year, concept)
                    newly_cached += 1
                else:
                    print(f"    âŒ è·å– {concept} æ—¶å‡ºé”™: {e}")
    
    # ä¿å­˜ç¼“å­˜æ›´æ–°
    if newly_cached > 0:
        save_invalid_concepts_cache()
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    print(f"\nğŸ“ˆ æŸ¥è¯¢ç»Ÿè®¡:")
    print(f"  æ€»æ•°: {total_concepts} ä¸ªæŒ‡æ ‡")
    print(f"  ç¼“å­˜è·³è¿‡: {cached_skipped} ä¸ª (æå‡æ€§èƒ½)")
    print(f"  APIè¯·æ±‚: {api_requested} ä¸ª")
    print(f"  æˆåŠŸè·å–: {successful_retrieved} ä¸ª")
    print(f"  æ–°å¢ç¼“å­˜: {newly_cached} ä¸ªæ— æ•ˆæŒ‡æ ‡")
    
    if cached_skipped > 0:
        efficiency_improvement = (cached_skipped / total_concepts) * 100
        print(f"  æ€§èƒ½æå‡: {efficiency_improvement:.1f}% (å‡å°‘äº† {cached_skipped} æ¬¡æ— æ•ˆAPIè¯·æ±‚)")
    
    if not all_data:
        print(f"\nâŒ æœªè·å–åˆ°ä»»ä½•æ•°æ®")
        return pd.DataFrame()
    
    # åˆ›å»ºDataFrame
    df = pd.DataFrame(all_data)
    
    # æŒ‰å¹´ä»½å’Œæ¦‚å¿µæ’åº
    df = df.sort_values(['year', 'concept'])
    
    print(f"\nâœ… æˆåŠŸè·å– {len(df)} æ¡è®°å½•")
    return df


def main():
    """ä¸»å‡½æ•°"""
    # åŠ è½½æŠ¥å‘ŠæŒ‡æ ‡æ˜ å°„
    metrics_mapping = load_report_metrics_mapping()
    
    # åŠ è½½ticker-CIKæ˜ å°„
    ticker_cik_map = load_ticker_cik_mapping()
    
    parser = argparse.ArgumentParser(
        description="SECæŠ¥å‘Šæ•°æ®è·å–å·¥å…·ï¼ˆå¢å¼ºç‰ˆï¼‰",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  python sec_report_fetcher_enhanced.py --company AAPL --report 10-K --year 2025
  python sec_report_fetcher_enhanced.py --cik 0000320193 --report 10-K --section "Balance Sheet" --year 2020-2025
  python sec_report_fetcher_enhanced.py --company MSFT --report 10-Q --year 2024 --section "Balance Sheet Summary"
        """
    )
    
    # æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯çš„ç‰¹æ®Šé€‰é¡¹
    help_parser = argparse.ArgumentParser(add_help=False)
    help_parser.add_argument('--help-sections', 
                            action='store_true',
                            help='æ˜¾ç¤ºå¯ç”¨çš„æŠ¥å‘Šéƒ¨åˆ†')
    help_parser.add_argument('--help-reports', 
                            action='store_true',
                            help='æ˜¾ç¤ºæ”¯æŒçš„æŠ¥å‘Šç±»å‹')
    help_parser.add_argument('--cache-stats', 
                            action='store_true',
                            help='æ˜¾ç¤ºç¼“å­˜ç»Ÿè®¡ä¿¡æ¯')
    
    # å…ˆè§£æå¸®åŠ©é€‰é¡¹
    help_args, _ = help_parser.parse_known_args()
    
    # æ˜¾ç¤ºæŠ¥å‘Šéƒ¨åˆ†å¸®åŠ©ä¿¡æ¯
    if help_args.help_sections:
        print("å¯ç”¨çš„æŠ¥å‘Šéƒ¨åˆ†:")
        if metrics_mapping:
            for report_type, report_data in metrics_mapping.items():
                print(f"\n{report_type}:")
                if 'sections' in report_data:
                    for section_name, metrics in report_data['sections'].items():
                        metric_count = len(metrics) if isinstance(metrics, list) else 0
                        print(f"  {section_name}: {metric_count} metrics")
        else:
            print("  Balance Sheet     - èµ„äº§è´Ÿå€ºè¡¨")
            print("  Income Statement  - æŸç›Šè¡¨")
            print("  Cash Flow         - ç°é‡‘æµé‡è¡¨")
        return
    
    # æ˜¾ç¤ºæŠ¥å‘Šç±»å‹å¸®åŠ©ä¿¡æ¯
    if help_args.help_reports:
        print("æ”¯æŒçš„æŠ¥å‘Šç±»å‹:")
        if metrics_mapping:
            for report_type, report_data in metrics_mapping.items():
                description = report_data.get('description', 'N/A')
                total_metrics = report_data.get('total_metrics', 0)
                print(f"  {report_type}: {description} ({total_metrics} metrics)")
        else:
            print("  10-K: å¹´åº¦æŠ¥å‘Š")
            print("  10-Q: å­£åº¦æŠ¥å‘Š")
        return
    
    # æ˜¾ç¤ºç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
    if help_args.cache_stats:
        print("ğŸ“Š æ— æ•ˆæŒ‡æ ‡ç¼“å­˜ç»Ÿè®¡:")
        load_invalid_concepts_cache()
        stats = get_cache_stats()
        
        print(f"  ç¼“å­˜æ–‡ä»¶: {stats['cache_file']}")
        print(f"  æ€»ç¼“å­˜æ•°: {stats['total_cached']} ä¸ªæ— æ•ˆæŒ‡æ ‡")
        print(f"  æœ‰æ•ˆç¼“å­˜: {stats['valid_count']} ä¸ª")
        print(f"  è¿‡æœŸç¼“å­˜: {stats['expired_count']} ä¸ª")
        if stats['last_updated']:
            print(f"  æœ€åæ›´æ–°: {stats['last_updated'].strftime('%Y-%m-%d %H:%M:%S')}")
        
        # æ˜¾ç¤ºæŒ‰å…¬å¸åˆ†ç»„çš„ç»Ÿè®¡
        if stats['company_stats']:
            print(f"\nğŸ¢ æŒ‰å…¬å¸åˆ†ç»„çš„ç¼“å­˜ç»Ÿè®¡:")
            for cik, count in sorted(stats['company_stats'].items()):
                print(f"  CIK {cik}: {count} ä¸ªæ— æ•ˆæŒ‡æ ‡")
        
        # æ˜¾ç¤ºæŒ‰æŠ¥å‘Šç±»å‹åˆ†ç»„çš„ç»Ÿè®¡
        if stats['report_type_stats']:
            print(f"\nğŸ“„ æŒ‰æŠ¥å‘Šç±»å‹åˆ†ç»„çš„ç¼“å­˜ç»Ÿè®¡:")
            for report_type, count in sorted(stats['report_type_stats'].items()):
                print(f"  {report_type}: {count} ä¸ªæ— æ•ˆæŒ‡æ ‡")
        
        if stats['valid_count'] > 0:
            print(f"\nğŸ“ˆ æ€§èƒ½æå‡: å¯èŠ‚çœ {stats['valid_count']} æ¬¡æ— æ•ˆAPIè¯·æ±‚")
            print(f"ğŸ¯ ç¼“å­˜è¦†ç›–èŒƒå›´: {len(stats['company_stats'])} å®¶å…¬å¸çš„ {len(stats['report_type_stats'])} ç§æŠ¥å‘Šç±»å‹")
        else:
            print(f"\nğŸ†• ç¼“å­˜ä¸ºç©ºï¼Œå°†åœ¨é¦–æ¬¡æŸ¥è¯¢åå»ºç«‹")
        return
    
    # å…¬å¸æ ‡è¯†å‚æ•°ç»„
    company_group = parser.add_mutually_exclusive_group(required=True)
    company_group.add_argument('--company', '-c', 
                              help='å…¬å¸è‚¡ç¥¨ä»£ç  (å¦‚: AAPL, MSFT)')
    company_group.add_argument('--cik', 
                              help='å…¬å¸CIKå·ç  (å¦‚: 0000320193)')
    
    # è·å–æ‰€æœ‰æ”¯æŒçš„æŠ¥å‘Šç±»å‹
    all_report_types = get_all_report_types(metrics_mapping)
    
    # å¿…éœ€å‚æ•°
    parser.add_argument('--report', '-r', 
                       required=True,
                       choices=all_report_types,
                       help='SECæŠ¥å‘Šç±»å‹')
    
    parser.add_argument('--year', '-y', 
                       required=True,
                       help='å¹´ä»½ (å¦‚: 2025 æˆ– 2020-2025)')
    
    # è·å–æŒ‡å®šæŠ¥å‘Šç±»å‹çš„æ‰€æœ‰éƒ¨åˆ†
    all_sections = []
    if '--report' in sys.argv:
        try:
            report_index = sys.argv.index('--report')
            if len(sys.argv) > report_index + 1:
                report_type = sys.argv[report_index + 1]
                all_sections = get_all_sections_for_report(report_type, metrics_mapping)
        except:
            pass
    
    # å¯é€‰å‚æ•°
    parser.add_argument('--section', '-s',
                       choices=all_sections if all_sections else None,
                       help='æŠ¥å‘Šéƒ¨åˆ†')
    
    parser.add_argument('--output', '-o',
                       help='è¾“å‡ºæ–‡ä»¶è·¯å¾„ (æ”¯æŒ .csv, .xlsx)')
    
    parser.add_argument('--user-agent',
                       default="SEC Report Fetcher <sec.report@example.com>",
                       help='User-Agentå­—ç¬¦ä¸²')
    
    args = parser.parse_args()
    
    try:
        # è§£æå¹´ä»½å‚æ•°
        years = parse_year_range(args.year)
        
        # ç¡®å®šå…¬å¸æ ‡è¯†
        company_id = args.cik if args.cik else args.company
        is_cik = bool(args.cik)
        
        # è·å–æ•°æ®
        df = fetch_sec_report_data(
            company_id=company_id,
            report_type=args.report,
            years=years,
            section=args.section,
            is_cik=is_cik,
            user_agent=args.user_agent,
            ticker_cik_map=ticker_cik_map
        )
        
        if df.empty:
            print("âŒ æœªè·å–åˆ°ä»»ä½•æ•°æ®")
            return
        
        # æ˜¾ç¤ºç»“æœ
        print(f"\nğŸ“Š æ•°æ®é¢„è§ˆ:")
        print("=" * 100)
        if args.section:
            print(f"å…¬å¸: {df.iloc[0]['company']}")
            print(f"æŠ¥å‘Šç±»å‹: {args.report}")
            print(f"æŠ¥å‘Šéƒ¨åˆ†: {args.section}")
            print(f"å¹´ä»½: {', '.join(map(str, years))}")
            print("=" * 100)
            
            # æŒ‰å¹´ä»½åˆ†ç»„æ˜¾ç¤º
            for year in sorted(df['year'].unique()):
                year_data = df[df['year'] == year]
                print(f"\n{year}å¹´æ•°æ®:")
                for _, row in year_data.iterrows():
                    print(f"  {row['concept']:40}: {row['formatted_value']:>15}")
        else:
            # æ˜¾ç¤ºæ‰€æœ‰æ•°æ®
            print(df[['year', 'concept', 'formatted_value', 'end_date']].to_string(index=False))
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        if args.output:
            try:
                if args.output.endswith('.csv'):
                    df.to_csv(args.output, index=False, encoding='utf-8')
                    print(f"\nğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ°: {args.output}")
                elif args.output.endswith('.xlsx'):
                    df.to_excel(args.output, index=False)
                    print(f"\nğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ°: {args.output}")
                else:
                    # é»˜è®¤ä¿å­˜ä¸ºCSV
                    output_file = args.output + '.csv'
                    df.to_csv(output_file, index=False, encoding='utf-8')
                    print(f"\nğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ°: {output_file}")
            except Exception as e:
                print(f"âš ï¸  ä¿å­˜æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        
        # æ˜¾ç¤ºç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
        cache_stats = get_cache_stats()
        if cache_stats['valid_count'] > 0:
            print(f"\nğŸ’¾ ç¼“å­˜ä¿¡æ¯: {cache_stats['valid_count']} ä¸ªæ— æ•ˆæŒ‡æ ‡å·²ç¼“å­˜ï¼Œæå‡åç»­æŸ¥è¯¢æ€§èƒ½")
        
        print(f"\nâœ… å®Œæˆ!")
        
    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()