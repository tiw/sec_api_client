#!/usr/bin/env python3
"""
SECæŠ¥å‘Šæ•°æ®è·å–å·¥å…·ï¼ˆæ•°æ®åº“ç‰ˆï¼‰

åŸºäºæ•°æ®åº“çš„SECæŠ¥å‘Šæ•°æ®è·å–ï¼Œæ”¯æŒï¼š
- æ•°æ®åº“ç¼“å­˜æœºåˆ¶ï¼Œé¿å…é‡å¤è·å–å·²æœ‰æ•°æ®
- æ™ºèƒ½çš„æ— æ•ˆæŒ‡æ ‡ç¼“å­˜
- å®Œæ•´çš„æ•°æ®ç®¡ç†å’Œç»Ÿè®¡
- æ”¯æŒSQLiteã€PostgreSQLå’ŒMySQL

ä½¿ç”¨ç¤ºä¾‹:
    python sec_report_fetcher_db.py --company AAPL --report 10-K --year 2024
    python sec_report_fetcher_db.py --cik 0000320193 --report 10-K --section "Balance Sheet" --year 2020-2024
    python sec_report_fetcher_db.py --company MSFT --report 10-Q --year 2024 --section "Balance Sheet Summary"
"""

import argparse
import sys
import os
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Union, Tuple

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '.'))

from src import SECClient, XBRLFramesClient, DocumentRetriever
from src.database.manager import DatabaseManager, get_default_sqlite_manager
from src.database.utils import DatabaseUtils
from src.database.models import Company, ReportType, ReportSection, Metric, FinancialData, DataFetchLog
import pandas as pd

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)


class SECFetcherDB:
    """åŸºäºæ•°æ®åº“çš„SECæ•°æ®è·å–å™¨"""
    
    def __init__(self, db_manager: DatabaseManager, user_agent: str = "SEC Report Fetcher (please-set-your-email@example.com)"):
        """
        åˆå§‹åŒ–SECæ•°æ®è·å–å™¨
        
        Args:
            db_manager: æ•°æ®åº“ç®¡ç†å™¨
            user_agent: User-Agentå­—ç¬¦ä¸²
        """
        self.db_manager = db_manager
        self.db_utils = DatabaseUtils(db_manager)
        self.user_agent = user_agent
        
        # åˆå§‹åŒ–SECå®¢æˆ·ç«¯
        self.sec_client = SECClient(user_agent=user_agent)
        self.xbrl_client = XBRLFramesClient(self.sec_client)
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.fetch_stats = {
            'total_metrics_requested': 0,
            'database_hits': 0,
            'cache_skips': 0,
            'api_requests': 0,
            'successful_fetches': 0,
            'new_cache_entries': 0,
            'errors': 0
        }
    
    def fetch_company_data(
        self,
        company_identifier: str,  # tickeræˆ–CIK
        report_type_code: str,
        fiscal_years: List[int],
        section_name: Optional[str] = None,
        force_refresh: bool = False
    ) -> Tuple[pd.DataFrame, Dict]:
        """
        è·å–å…¬å¸è´¢åŠ¡æ•°æ®
        
        Args:
            company_identifier: å…¬å¸æ ‡è¯†ï¼ˆtickeræˆ–CIKï¼‰
            report_type_code: æŠ¥å‘Šç±»å‹ä»£ç 
            fiscal_years: è´¢æ”¿å¹´åº¦åˆ—è¡¨
            section_name: æŠ¥å‘Šéƒ¨åˆ†åç§°ï¼ˆå¯é€‰ï¼‰
            force_refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°ï¼ˆå¿½ç•¥ç¼“å­˜ï¼‰
            
        Returns:
            (DataFrame, ç»Ÿè®¡ä¿¡æ¯å­—å…¸)
        """
        start_time = datetime.now()
        
        # é‡ç½®ç»Ÿè®¡ä¿¡æ¯
        self._reset_stats()
        
        # è·å–å…¬å¸ä¿¡æ¯
        company = self.db_utils.get_company_by_ticker(company_identifier) or \
                 self.db_utils.get_company_by_cik(company_identifier)
        
        if not company:
            # å°è¯•é€šè¿‡SEC APIè·å–å…¬å¸ä¿¡æ¯
            logger.info(f"ğŸ” å…¬å¸ {company_identifier} åœ¨æ•°æ®åº“ä¸­æœªæ‰¾åˆ°ï¼Œå°è¯•é€šè¿‡SEC APIè·å–...")
            company = self._fetch_and_save_company(company_identifier)
            if not company:
                raise ValueError(f"æœªæ‰¾åˆ°å…¬å¸: {company_identifier}")
        
        logger.info(f"ğŸ¢ å…¬å¸: {company.name} (CIK: {company.cik}, Ticker: {company.ticker})")
        
        # è·å–æŒ‡æ ‡åˆ—è¡¨
        metrics = self._get_metrics_to_fetch(report_type_code, section_name)
        if not metrics:
            raise ValueError(f"æœªæ‰¾åˆ° {report_type_code} æŠ¥å‘Šçš„æŒ‡æ ‡")
        
        logger.info(f"ğŸ“Š æŠ¥å‘Šç±»å‹: {report_type_code}")
        logger.info(f"ğŸ“… å¹´ä»½: {', '.join(map(str, fiscal_years))}")
        logger.info(f"ğŸ“ˆ æ€»è®¡ {len(metrics)} ä¸ªæŒ‡æ ‡éœ€è¦å¤„ç†")
        
        if section_name:
            logger.info(f"ğŸ“„ æŠ¥å‘Šéƒ¨åˆ†: {section_name}")
        
        # åˆ›å»ºæ•°æ®è·å–æ—¥å¿—
        fetch_log = self._create_fetch_log(company, report_type_code, fiscal_years)
        
        try:
            # æ”¶é›†æ‰€æœ‰æ•°æ®
            all_data = []
            
            for year in fiscal_years:
                logger.info(f"\nğŸ“… æ­£åœ¨å¤„ç† {year} å¹´æ•°æ®...")
                year_data = self._fetch_year_data(
                    company, report_type_code, year, metrics, force_refresh
                )
                all_data.extend(year_data)
            
            # æ›´æ–°è·å–æ—¥å¿—
            self._update_fetch_log(fetch_log, 'SUCCESS', start_time)
            
            # åˆ›å»ºDataFrame
            if all_data:
                df = pd.DataFrame(all_data)
                df = df.sort_values(['fiscal_year', 'metric_name'])
                logger.info(f"\nâœ… æˆåŠŸè·å– {len(df)} æ¡è®°å½•")
            else:
                df = pd.DataFrame()
                logger.info(f"\nâŒ æœªè·å–åˆ°ä»»ä½•æ•°æ®")
            
            return df, self.fetch_stats
            
        except Exception as e:
            # æ›´æ–°è·å–æ—¥å¿—ä¸ºå¤±è´¥çŠ¶æ€
            self._update_fetch_log(fetch_log, 'FAILED', start_time, str(e))
            raise
    
    def _fetch_and_save_company(self, company_identifier: str) -> Optional[Company]:
        """é€šè¿‡SEC APIè·å–å¹¶ä¿å­˜å…¬å¸ä¿¡æ¯"""
        try:
            # åˆ¤æ–­æ˜¯CIKè¿˜æ˜¯ticker
            if company_identifier.isdigit() or len(company_identifier) == 10:
                # CIKæ ¼å¼
                cik = company_identifier.zfill(10)
                submissions = self.sec_client.get_company_submissions(cik)
                company_name = submissions.get('names', ['Unknown Company'])[0] if submissions.get('names') else 'Unknown Company'
                ticker = None  # ä»submissionsä¸­å¯èƒ½å¯ä»¥è·å–tickerï¼Œè¿™é‡Œç®€åŒ–å¤„ç†
            else:
                # tickeræ ¼å¼
                company_info = self.sec_client.search_company_by_ticker(company_identifier)
                if not company_info:
                    return None
                cik = company_info['cik']
                company_name = company_info['title']
                ticker = company_identifier.upper()
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            with self.db_manager.get_session() as session:
                company = Company(
                    cik=cik,
                    ticker=ticker,
                    name=company_name,
                    is_active=True
                )
                session.add(company)
                session.commit()
                session.refresh(company)
                
                logger.info(f"âœ… å·²ä¿å­˜æ–°å…¬å¸åˆ°æ•°æ®åº“: {company_name} (CIK: {cik})")
                return company
                
        except Exception as e:
            logger.error(f"è·å–å…¬å¸ä¿¡æ¯å¤±è´¥: {e}")
            return None
    
    def _get_metrics_to_fetch(self, report_type_code: str, section_name: Optional[str] = None) -> List[Metric]:
        """è·å–éœ€è¦æŠ“å–çš„æŒ‡æ ‡åˆ—è¡¨"""
        if section_name:
            # è·å–æŒ‡å®šéƒ¨åˆ†çš„æŒ‡æ ‡
            return self.db_utils.get_section_metrics(report_type_code, section_name)
        else:
            # è·å–è¯¥æŠ¥å‘Šç±»å‹çš„æ‰€æœ‰æŒ‡æ ‡
            sections = self.db_utils.get_report_sections(report_type_code)
            all_metrics = []
            for section in sections:
                metrics = self.db_utils.get_section_metrics(report_type_code, section.section_name)
                all_metrics.extend(metrics)
            return all_metrics
    
    def _fetch_year_data(
        self,
        company: Company,
        report_type_code: str,
        fiscal_year: int,
        metrics: List[Metric],
        force_refresh: bool
    ) -> List[Dict]:
        """è·å–æŒ‡å®šå¹´ä»½çš„æ•°æ®"""
        year_data = []
        
        self.fetch_stats['total_metrics_requested'] += len(metrics)
        
        for metric in metrics:
            try:
                # æ£€æŸ¥æ•°æ®åº“ä¸­æ˜¯å¦å·²æœ‰æ•°æ®
                if not force_refresh:
                    existing_data = self._check_existing_data(company, metric, fiscal_year)
                    if existing_data:
                        # ä»æ•°æ®åº“è·å–
                        year_data.append(self._format_data_from_db(existing_data))
                        self.fetch_stats['database_hits'] += 1
                        logger.debug(f"  ğŸ’¾ ä»æ•°æ®åº“è·å– {metric.metric_name}")
                        continue
                    
                    # æ£€æŸ¥æ— æ•ˆç¼“å­˜
                    if self.db_utils.is_metric_cached_invalid(
                        company.cik, report_type_code, fiscal_year, metric.metric_name
                    ):
                        logger.debug(f"  â© è·³è¿‡ {metric.metric_name} (ç¼“å­˜ä¸­å·²çŸ¥æ— æ•ˆ)")
                        self.fetch_stats['cache_skips'] += 1
                        continue
                
                # ä»SEC APIè·å–æ•°æ®
                logger.debug(f"  ğŸ”„ ä»SEC APIè·å– {metric.metric_name}...")
                self.fetch_stats['api_requests'] += 1
                
                data = self._fetch_metric_from_api(company, metric, fiscal_year, report_type_code)
                if data:
                    # ä¿å­˜åˆ°æ•°æ®åº“
                    self._save_financial_data(data)
                    year_data.append(data)
                    self.fetch_stats['successful_fetches'] += 1
                    logger.debug(f"    âœ… {metric.metric_name}: {data.get('formatted_value', 'N/A')}")
                else:
                    # æ·»åŠ åˆ°æ— æ•ˆç¼“å­˜
                    self.db_utils.add_invalid_metric_cache(
                        company.cik, report_type_code, fiscal_year, metric.metric_name, "NO_DATA"
                    )
                    self.fetch_stats['new_cache_entries'] += 1
                    logger.debug(f"    âŒ {metric.metric_name} æ— æ•°æ®ï¼Œå·²åŠ å…¥ç¼“å­˜")
                    
            except Exception as e:
                logger.error(f"è·å– {metric.metric_name} æ—¶å‡ºé”™: {e}")
                self.fetch_stats['errors'] += 1
                
                # å¦‚æœæ˜¯404é”™è¯¯ï¼ŒåŠ å…¥æ— æ•ˆç¼“å­˜
                if "404" in str(e) or "Not Found" in str(e):
                    self.db_utils.add_invalid_metric_cache(
                        company.cik, report_type_code, fiscal_year, metric.metric_name, "404_NOT_FOUND"
                    )
                    self.fetch_stats['new_cache_entries'] += 1
        
        return year_data
    
    def _check_existing_data(self, company: Company, metric: Metric, fiscal_year: int) -> Optional[FinancialData]:
        """æ£€æŸ¥æ•°æ®åº“ä¸­æ˜¯å¦å·²æœ‰æ•°æ®"""
        with self.db_manager.get_session() as session:
            return session.query(FinancialData).filter_by(
                company_id=company.id,
                metric_id=metric.id,
                fiscal_year=fiscal_year
            ).first()
    
    def _fetch_metric_from_api(
        self,
        company: Company,
        metric: Metric,
        fiscal_year: int,
        report_type_code: str
    ) -> Optional[Dict]:
        """ä»SEC APIè·å–æŒ‡æ ‡æ•°æ®"""
        try:
            # è·å–å…¬å¸ç‰¹å®šæ¦‚å¿µçš„å†å²æ•°æ®
            concept_data = self.xbrl_client.get_company_concept_data(
                cik=company.cik,
                concept=metric.metric_name
            )
            
            if not concept_data or 'units' not in concept_data:
                return None
            
            # æŸ¥æ‰¾USDå•ä½æ•°æ®
            unit_data = concept_data['units'].get('USD', [])
            if not unit_data:
                return None
            
            # æŸ¥æ‰¾æŒ‡å®šå¹´ä»½å’ŒæŠ¥å‘Šç±»å‹çš„æ•°æ®
            for item in unit_data:
                item_year = item.get('fy', 0)
                item_form = item.get('form', '').upper()
                
                if item_year == fiscal_year and item_form == report_type_code.upper():
                    # æ‰¾åˆ°åŒ¹é…çš„æ•°æ®
                    value = item.get('val', 0)
                    
                    # æ ¼å¼åŒ–æ•°å€¼
                    if isinstance(value, (int, float)):
                        if abs(value) >= 1e9:
                            formatted_value = f"${value/1e9:.2f}B"
                        elif abs(value) >= 1e6:
                            formatted_value = f"${value/1e6:.2f}M"
                        elif abs(value) >= 1e3:
                            formatted_value = f"${value/1e3:.2f}K"
                        else:
                            formatted_value = f"${value:,.2f}"
                    else:
                        formatted_value = str(value)
                    
                    return {
                        'company_id': company.id,
                        'company_cik': company.cik,
                        'company_ticker': company.ticker,
                        'company_name': company.name,
                        'metric_id': metric.id,
                        'metric_name': metric.metric_name,
                        'section_id': metric.section_id,
                        'fiscal_year': fiscal_year,
                        'fiscal_period': item.get('fp', 'FY'),
                        'period_start_date': item.get('start', ''),
                        'period_end_date': item.get('end', ''),
                        'filed_date': item.get('filed', ''),
                        'value': value,
                        'formatted_value': formatted_value,
                        'unit': 'USD',
                        'frame': item.get('frame', ''),
                        'form_type': item.get('form', ''),
                        'accession_number': item.get('accn', ''),
                        'data_source': 'SEC_API'
                    }
            
            return None
            
        except Exception as e:
            logger.error(f"APIè·å–å¤±è´¥: {e}")
            raise
    
    def _save_financial_data(self, data: Dict):
        """ä¿å­˜è´¢åŠ¡æ•°æ®åˆ°æ•°æ®åº“"""
        try:
            with self.db_manager.get_session() as session:
                # è·å–æŠ¥å‘Šç±»å‹
                report_type = session.query(ReportType).join(ReportSection).filter(
                    ReportSection.id == data['section_id']
                ).first()
                
                if not report_type:
                    logger.error(f"æœªæ‰¾åˆ°å¯¹åº”çš„æŠ¥å‘Šç±»å‹ï¼Œsection_id: {data['section_id']}")
                    return
                
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                existing = session.query(FinancialData).filter_by(
                    company_id=data['company_id'],
                    metric_id=data['metric_id'],
                    fiscal_year=data['fiscal_year'],
                    period_end_date=data['period_end_date']
                ).first()
                
                if existing:
                    # æ›´æ–°ç°æœ‰è®°å½•
                    existing.value = data['value']
                    existing.formatted_value = data['formatted_value']
                    existing.updated_at = datetime.now()
                else:
                    # åˆ›å»ºæ–°è®°å½•
                    financial_data = FinancialData(
                        company_id=data['company_id'],
                        report_type_id=report_type.id,
                        section_id=data['section_id'],
                        metric_id=data['metric_id'],
                        fiscal_year=data['fiscal_year'],
                        fiscal_period=data.get('fiscal_period'),
                        period_start_date=data.get('period_start_date'),
                        period_end_date=data.get('period_end_date'),
                        filed_date=data.get('filed_date'),
                        value=data['value'],
                        formatted_value=data['formatted_value'],
                        unit=data.get('unit', 'USD'),
                        frame=data.get('frame'),
                        form_type=data.get('form_type'),
                        accession_number=data.get('accession_number'),
                        data_source=data.get('data_source', 'SEC_API')
                    )
                    session.add(financial_data)
                
                session.commit()
                
        except Exception as e:
            logger.error(f"ä¿å­˜è´¢åŠ¡æ•°æ®å¤±è´¥: {e}")
    
    def _format_data_from_db(self, financial_data: FinancialData) -> Dict:
        """æ ¼å¼åŒ–æ•°æ®åº“ä¸­çš„æ•°æ®ä¸ºç»Ÿä¸€æ ¼å¼"""
        with self.db_manager.get_session() as session:
            company = session.query(Company).filter_by(id=financial_data.company_id).first()
            metric = session.query(Metric).filter_by(id=financial_data.metric_id).first()
            
            return {
                'company_id': company.id,
                'company_cik': company.cik,
                'company_ticker': company.ticker,
                'company_name': company.name,
                'metric_id': metric.id,
                'metric_name': metric.metric_name,
                'section_id': metric.section_id,
                'fiscal_year': financial_data.fiscal_year,
                'fiscal_period': financial_data.fiscal_period,
                'period_start_date': financial_data.period_start_date,
                'period_end_date': financial_data.period_end_date,
                'filed_date': financial_data.filed_date,
                'value': financial_data.value,
                'formatted_value': financial_data.formatted_value,
                'unit': financial_data.unit,
                'frame': financial_data.frame,
                'form_type': financial_data.form_type,
                'accession_number': financial_data.accession_number,
                'data_source': financial_data.data_source
            }
    
    def _create_fetch_log(self, company: Company, report_type_code: str, fiscal_years: List[int]) -> DataFetchLog:
        """åˆ›å»ºæ•°æ®è·å–æ—¥å¿—"""
        with self.db_manager.get_session() as session:
            report_type = session.query(ReportType).filter_by(type_code=report_type_code).first()
            
            fetch_log = DataFetchLog(
                company_id=company.id,
                report_type_id=report_type.id if report_type else None,
                fiscal_year=fiscal_years[0] if len(fiscal_years) == 1 else None,  # å¦‚æœæ˜¯å¤šå¹´ï¼Œç•™ç©º
                status='IN_PROGRESS'
            )
            session.add(fetch_log)
            session.commit()
            session.refresh(fetch_log)
            
            return fetch_log
    
    def _update_fetch_log(
        self,
        fetch_log: DataFetchLog,
        status: str,
        start_time: datetime,
        error_message: Optional[str] = None
    ):
        """æ›´æ–°æ•°æ®è·å–æ—¥å¿—"""
        try:
            with self.db_manager.get_session() as session:
                log = session.query(DataFetchLog).filter_by(id=fetch_log.id).first()
                if log:
                    log.status = status
                    log.completed_at = datetime.now()
                    log.fetch_duration_seconds = (datetime.now() - start_time).total_seconds()
                    log.total_metrics = self.fetch_stats['total_metrics_requested']
                    log.successful_metrics = self.fetch_stats['successful_fetches']
                    log.cached_skips = self.fetch_stats['cache_skips']
                    log.new_invalid_cache = self.fetch_stats['new_cache_entries']
                    log.api_requests_count = self.fetch_stats['api_requests']
                    log.error_message = error_message
                    
                    session.commit()
                    
        except Exception as e:
            logger.error(f"æ›´æ–°è·å–æ—¥å¿—å¤±è´¥: {e}")
    
    def _reset_stats(self):
        """é‡ç½®ç»Ÿè®¡ä¿¡æ¯"""
        for key in self.fetch_stats:
            self.fetch_stats[key] = 0
    
    def get_performance_stats(self) -> Dict:
        """è·å–æ€§èƒ½ç»Ÿè®¡ä¿¡æ¯"""
        total_requests = self.fetch_stats['database_hits'] + self.fetch_stats['api_requests']
        cache_efficiency = 0
        if total_requests > 0:
            cache_efficiency = (self.fetch_stats['database_hits'] + self.fetch_stats['cache_skips']) / total_requests * 100
        
        return {
            **self.fetch_stats,
            'total_requests': total_requests,
            'cache_efficiency_percentage': cache_efficiency,
            'api_success_rate': (
                self.fetch_stats['successful_fetches'] / self.fetch_stats['api_requests'] * 100
                if self.fetch_stats['api_requests'] > 0 else 0
            )
        }


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="SECæŠ¥å‘Šæ•°æ®è·å–å·¥å…·ï¼ˆæ•°æ®åº“ç‰ˆï¼‰",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  python sec_report_fetcher_db.py --company AAPL --report 10-K --year 2024
  python sec_report_fetcher_db.py --cik 0000320193 --report 10-K --section "Balance Sheet" --year 2020-2024
  python sec_report_fetcher_db.py --company MSFT --report 10-Q --year 2024 --section "Balance Sheet Summary"
  python sec_report_fetcher_db.py --db-stats  # æ˜¾ç¤ºæ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯
        """
    )
    
    # å…¬å¸æ ‡è¯†å‚æ•°ç»„
    company_group = parser.add_mutually_exclusive_group()
    company_group.add_argument('--company', '-c', 
                              help='å…¬å¸è‚¡ç¥¨ä»£ç  (å¦‚: AAPL, MSFT)')
    company_group.add_argument('--cik', 
                              help='å…¬å¸CIKå·ç  (å¦‚: 0000320193)')
    
    # æŸ¥è¯¢å‚æ•°
    parser.add_argument('--report', '-r', 
                       help='SECæŠ¥å‘Šç±»å‹ (å¦‚: 10-K, 10-Q)')
    
    parser.add_argument('--year', '-y', 
                       help='å¹´ä»½ (å¦‚: 2024 æˆ– 2020-2024)')
    
    parser.add_argument('--section', '-s',
                       help='æŠ¥å‘Šéƒ¨åˆ† (å¦‚: Balance Sheet)')
    
    # è¾“å‡ºå’Œè¡Œä¸ºå‚æ•°
    parser.add_argument('--output', '-o',
                       help='è¾“å‡ºæ–‡ä»¶è·¯å¾„ (æ”¯æŒ .csv, .xlsx)')
    
    parser.add_argument('--force-refresh', 
                       action='store_true',
                       help='å¼ºåˆ¶åˆ·æ–°æ•°æ®ï¼Œå¿½ç•¥ç¼“å­˜')
    
    # æ•°æ®åº“å‚æ•°
    parser.add_argument('--db-url',
                       help='æ•°æ®åº“è¿æ¥URL (é»˜è®¤ä½¿ç”¨SQLite)')
    
    # ç»Ÿè®¡ä¿¡æ¯å‚æ•°
    parser.add_argument('--db-stats', 
                       action='store_true',
                       help='æ˜¾ç¤ºæ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯')
    
    parser.add_argument('--cache-stats', 
                       action='store_true',
                       help='æ˜¾ç¤ºç¼“å­˜ç»Ÿè®¡ä¿¡æ¯')
    
    parser.add_argument('--user-agent',
                       default="SEC Report Fetcher (please-set-your-email@example.com)",
                       help='User-Agentå­—ç¬¦ä¸²ï¼Œå»ºè®®æ ¼å¼ï¼š"æ‚¨çš„å§“å <your@email.com>"')
    
    # æ—¥å¿—çº§åˆ«
    parser.add_argument('--log-level',
                       choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'],
                       default='INFO',
                       help='æ—¥å¿—çº§åˆ«')
    
    args = parser.parse_args()
    
    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=getattr(logging, args.log_level),
        format='%(asctime)s - %(levelname)s - %(message)s'
    )
    
    try:
        # è·å–æ•°æ®åº“ç®¡ç†å™¨
        if args.db_url:
            db_manager = DatabaseManager(args.db_url)
            if not db_manager.connect():
                print("âŒ æ•°æ®åº“è¿æ¥å¤±è´¥")
                return 1
        else:
            db_manager = get_default_sqlite_manager()
        
        # ç¡®ä¿è¡¨å·²åˆ›å»º
        if not db_manager.create_tables():
            print("âš ï¸  åˆ›å»ºæ•°æ®åº“è¡¨å¤±è´¥")
        
        db_utils = DatabaseUtils(db_manager)
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        if args.db_stats:
            stats = db_utils.get_database_statistics()
            print("ğŸ“Š æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯:")
            for key, value in stats.items():
                print(f"  {key}: {value}")
            return 0
        
        if args.cache_stats:
            cache_stats = db_utils.get_cache_statistics()
            print("ğŸ’¾ ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯:")
            for key, value in cache_stats.items():
                print(f"  {key}: {value}")
            return 0
        
        # éªŒè¯å¿…éœ€å‚æ•°
        if not (args.company or args.cik):
            print("âŒ è¯·æŒ‡å®šå…¬å¸æ ‡è¯† (--company æˆ– --cik)")
            return 1
        
        if not args.report:
            print("âŒ è¯·æŒ‡å®šæŠ¥å‘Šç±»å‹ (--report)")
            return 1
        
        if not args.year:
            print("âŒ è¯·æŒ‡å®šå¹´ä»½ (--year)")
            return 1
        
        # è§£æå¹´ä»½
        if '-' in args.year:
            start_year, end_year = map(int, args.year.split('-'))
            years = list(range(start_year, end_year + 1))
        else:
            years = [int(args.year)]
        
        # åˆ›å»ºè·å–å™¨
        fetcher = SECFetcherDB(db_manager, args.user_agent)
        
        # ç¡®å®šå…¬å¸æ ‡è¯†
        company_id = args.cik if args.cik else args.company
        
        print(f"ğŸš€ å¼€å§‹è·å–æ•°æ®...")
        print(f"   å…¬å¸: {company_id}")
        print(f"   æŠ¥å‘Šç±»å‹: {args.report}")
        print(f"   å¹´ä»½: {', '.join(map(str, years))}")
        if args.section:
            print(f"   æŠ¥å‘Šéƒ¨åˆ†: {args.section}")
        if args.force_refresh:
            print(f"   ğŸ”„ å¼ºåˆ¶åˆ·æ–°æ¨¡å¼")
        print(f"\nâš ï¸  æç¤º: ä¸ºéµå®ˆSECæœåŠ¡å™¨æ”¿ç­–ï¼Œå»ºè®®åœ¨ç¾å›½ä¸šåŠ¡æ—¶é—´å¤–ä½¿ç”¨")
        
        # è·å–æ•°æ®
        df, stats = fetcher.fetch_company_data(
            company_identifier=company_id,
            report_type_code=args.report,
            fiscal_years=years,
            section_name=args.section,
            force_refresh=args.force_refresh
        )
        
        # æ˜¾ç¤ºç»“æœ
        if not df.empty:
            print(f"\nğŸ“Š æ•°æ®é¢„è§ˆ:")
            print("=" * 100)
            
            # æ˜¾ç¤ºæŒ‰å¹´ä»½åˆ†ç»„çš„æ•°æ®
            for year in sorted(df['fiscal_year'].unique()):
                year_data = df[df['fiscal_year'] == year]
                print(f"\n{year}å¹´æ•°æ® ({len(year_data)} æ¡è®°å½•):")
                
                # æ˜¾ç¤ºå‰10æ¡è®°å½•
                display_data = year_data.head(10)
                for _, row in display_data.iterrows():
                    print(f"  {row['metric_name']:40}: {row['formatted_value']:>15}")
                
                if len(year_data) > 10:
                    print(f"  ... è¿˜æœ‰ {len(year_data) - 10} æ¡è®°å½•")
            
            # ä¿å­˜åˆ°æ–‡ä»¶
            if args.output:
                try:
                    if args.output.endswith('.csv'):
                        df.to_csv(args.output, index=False, encoding='utf-8')
                        print(f"\nğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ°: {args.output}")
                    elif args.output.endswith('.xlsx'):
                        df.to_excel(args.output, index=False)
                        print(f"\nğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ°: {args.output}")
                    else:
                        # é»˜è®¤ä¿å­˜ä¸ºCSV
                        output_file = args.output + '.csv'
                        df.to_csv(output_file, index=False, encoding='utf-8')
                        print(f"\nğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ°: {output_file}")
                except Exception as e:
                    print(f"âš ï¸  ä¿å­˜æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        else:
            print(f"\nâŒ æœªè·å–åˆ°ä»»ä½•æ•°æ®")
        
        # æ˜¾ç¤ºæ€§èƒ½ç»Ÿè®¡
        perf_stats = fetcher.get_performance_stats()
        print(f"\nğŸ“ˆ æ€§èƒ½ç»Ÿè®¡:")
        print(f"  æ•°æ®åº“å‘½ä¸­: {perf_stats['database_hits']} æ¬¡")
        print(f"  ç¼“å­˜è·³è¿‡: {perf_stats['cache_skips']} æ¬¡")
        print(f"  APIè¯·æ±‚: {perf_stats['api_requests']} æ¬¡")
        print(f"  æˆåŠŸè·å–: {perf_stats['successful_fetches']} æ¬¡")
        print(f"  ç¼“å­˜æ•ˆç‡: {perf_stats['cache_efficiency_percentage']:.1f}%")
        
        print(f"\nâœ… å®Œæˆ!")
        return 0
        
    except Exception as e:
        logger.error(f"ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
        print(f"âŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
        return 1
    
    finally:
        if 'db_manager' in locals():
            db_manager.close()


if __name__ == "__main__":
    exit(main())